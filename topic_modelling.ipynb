{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modelling_spacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwlEnNvQJNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AZPes5RSYG2",
        "colab_type": "text"
      },
      "source": [
        "# 0. Preliminary step to get sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRiBwgFTg2p",
        "colab_type": "text"
      },
      "source": [
        "This preliminary step is reproducing Lorella's workflow Python file:\n",
        "https://i-lab.public.data.uu.nl/vault-ocex/ChroniclItaly%20-%20Italian%20American%20newspapers%20corpus%20from%201898%20to%201920%5B1529330521%5D/original/\n",
        "I just added a folder \"data_1\" to keep all files in one folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK81EVJim0Jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e4ae4b4-64e4-4603-f20a-8caa08764afe"
      },
      "source": [
        "mkdir 'data1'"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data1’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O_c4pYzXsP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base URL\n",
        "chronam = 'https://chroniclingamerica.loc.gov/'\n",
        "\n",
        "# Chronicling America search results\n",
        "results = 'https://chroniclingamerica.loc.gov/search/pages/results/?date1=1880&date2=1920&searchType=advanced&language=ita&sequence=1&lccn=2012271201&lccn=sn85066408&lccn=sn85055164&lccn=sn85054967&lccn=sn88064299&lccn=sn84037024&lccn=sn84037025&lccn=sn86092310&proxdistance=5&state=California&state=District+of+Columbia&state=Massachusetts&state=Pennsylvania&state=Piedmont&state=Vermont&state=West+Virginia&rows=100&ortext=&proxtext=&phrasetext=&andtext=&dateFilterType=yearRange&page=11&sort=date'\n",
        "\n",
        "# Count to keep track of downloaded files\n",
        "count = 0\n",
        "\n",
        "# Gets search results in JSON format\n",
        "results_json = results + '&format=json'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQwqRYbydrq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns JSON \n",
        "def get_json(url):\n",
        "    data = requests.get(url)\n",
        "    return(json.loads(data.content))\n",
        "    \n",
        "data = get_json(results_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjv32dwDndnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cycle through JSON results\n",
        "for page in data['items']:\n",
        "    # Create URL\n",
        "    hit = str(page['id'])\n",
        "    seed = hit + 'ocr.txt'\n",
        "    download_url = chronam + seed\n",
        " \n",
        "    # Create file name\n",
        "    file_name = download_url.replace('/', '_')\n",
        "    file_name = 'data1/' + file_name[41:]\n",
        "    \n",
        "    # Download .txt of the page\n",
        "    urllib.request.urlretrieve(download_url, str(file_name))\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUvuIpuzT8ke",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTOrDXSYUIc3",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Grouping all texts files\n",
        "A dataframe is first created to keep individual files at their initial state, and the name of each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u857KfY9WXN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5FNWdVJT1v8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list of the file names\n",
        "files_list = os.listdir('data1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lLD0OpiXv5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#insert file names into a df\n",
        "sources = pd.DataFrame(files_list, columns=['file_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgOwPnqCfAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to read the content of the text files\n",
        "def readTxtContent(fileName):\n",
        "  with open('data1/' + fileName, 'r') as file:\n",
        "    return ' ' + file.read().replace('\\n', ' ') + ' '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEVIKHziQv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding a column to the dataframe containing file content\n",
        "sources['file_content'] = sources['file_name'].apply(lambda x: readTxtContent(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ffdAsOXQSBe",
        "colab_type": "code",
        "outputId": "a7bdc4f3-a9ce-4eda-91a5-e84ded4bd4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# for verification purposes later, count the nr of characters for each content\n",
        "sources['file_len'] = sources['file_content'].apply(lambda x: len(x))\n",
        "sources['file_len'].sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1779770"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwTwsGsED8uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable containing all texts together\n",
        "corpus = ''\n",
        "for i in range(len(sources)):\n",
        "  corpus += sources['file_content'][i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBu87u_SSM-9",
        "colab_type": "code",
        "outputId": "60acaf3b-28e7-4776-bd43-573ebd1ee0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check length\n",
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1779770"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybCetXHi9m-y",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Pre-processing options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEmwoDjMPmxa",
        "colab_type": "text"
      },
      "source": [
        "Options for the user to work on lower cased version, exclude short words, remove punctuation, remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZjtQSrV_lX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "#setting up for the language\n",
        "from spacy.lang.it import Italian\n",
        "nlp = Italian()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-H9vA9z_zmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenize with the language defaults\n",
        "\n",
        "tokenizer = Tokenizer(nlp.vocab)\n",
        "tokens = tokenizer(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeflceKM_7OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lower case tokens\n",
        "tokens_low = [token.lower_ for token in tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txWZd_OrIZ53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokens excluding punctuation, white spaces, and words smaller than 3 letters\n",
        "tokens_punct_size = [token.orth_ for token in tokens if not token.is_punct | token.is_space | len(token.text) < 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdeaRM_DQrJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment last line of this cell to show list of default Italian stopwords\n",
        "from spacy.lang.it.stop_words import STOP_WORDS\n",
        "# STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnC1H7HbI-tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combining all of the above and excluding default stop words list\n",
        "tokens_nostop = [token.lower_ for token in tokens if not (token.is_stop or token.is_punct or token.is_space or len(token.text) < 4)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM57noAZMUWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# note: spacy seems not to always remove punctuation within tokens, the reasons/modalities should be further looked into \n",
        "# a workaround would be to strip the corpus from punctuation before tokenizing with spacy, but as spacy uses\n",
        "# punctuation to determine some functions of words in sentences, one might lose some of spacy's functionalities.\n",
        "# I will look into this more in details at a later stage and start with the default functionalities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ez-6QnSpPNRa",
        "colab": {}
      },
      "source": [
        "# uncomment last line of this cell to show list of default Italian stopwords\n",
        "from spacy.lang.it.stop_words import STOP_WORDS\n",
        "# STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW0gKNlhPOWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to add/remove stop words depending on user input\n",
        "# nlp.Defaults.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\",}\n",
        "# nlp.Defaults.stop_words -= {\"whatever\", \"whenever\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odyz9sWNTraN",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Stem "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tegjxs6apC6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming is available via NLTK and not Spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fDKhXmBUD0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhg56o_1LeA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize with needed language\n",
        "stemmer = SnowballStemmer(\"italian\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDC3mIa3WzFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmed_corpus = [stemmer.stem(w) for w in tokens_nostop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4prU53t7pV90",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtIlSxFUX2zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the following returns a non lower cased form of the token, I need to find how to combine lower case form \n",
        "# and lemmatized form"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUmkTpHhWvHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_lemma = [token.lemma_ for token in tokens if not (token.is_stop or token.is_punct or token.is_space or len(token.text) < 4)]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}