{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyldavis_stats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwlEnNvQJNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AZPes5RSYG2",
        "colab_type": "text"
      },
      "source": [
        "# 0. Preliminary step to get sample data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRiBwgFTg2p",
        "colab_type": "text"
      },
      "source": [
        "This preliminary step is reproducing Lorella's workflow Python file:\n",
        "https://i-lab.public.data.uu.nl/vault-ocex/ChroniclItaly%20-%20Italian%20American%20newspapers%20corpus%20from%201898%20to%201920%5B1529330521%5D/original/\n",
        "I just added a folder \"data_1\" to keep all files in one folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK81EVJim0Jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f79f6562-72b6-4d04-8653-192886efb9a0"
      },
      "source": [
        "mkdir 'data1'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data1’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O_c4pYzXsP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base URL\n",
        "chronam = 'https://chroniclingamerica.loc.gov/'\n",
        "\n",
        "# Chronicling America search results\n",
        "results = 'https://chroniclingamerica.loc.gov/search/pages/results/?date1=1880&date2=1920&searchType=advanced&language=ita&sequence=1&lccn=2012271201&lccn=sn85066408&lccn=sn85055164&lccn=sn85054967&lccn=sn88064299&lccn=sn84037024&lccn=sn84037025&lccn=sn86092310&proxdistance=5&state=California&state=District+of+Columbia&state=Massachusetts&state=Pennsylvania&state=Piedmont&state=Vermont&state=West+Virginia&rows=100&ortext=&proxtext=&phrasetext=&andtext=&dateFilterType=yearRange&page=11&sort=date'\n",
        "\n",
        "# Count to keep track of downloaded files\n",
        "count = 0\n",
        "\n",
        "# Gets search results in JSON format\n",
        "results_json = results + '&format=json'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQwqRYbydrq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns JSON \n",
        "def get_json(url):\n",
        "    data = requests.get(url)\n",
        "    return(json.loads(data.content))\n",
        "    \n",
        "data = get_json(results_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjv32dwDndnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files_list = []\n",
        "# Cycle through JSON results\n",
        "for page in data['items']:\n",
        "    # Create URL\n",
        "    hit = str(page['id'])\n",
        "    seed = hit + 'ocr.txt'\n",
        "    download_url = chronam + seed\n",
        " \n",
        "    # Create file name\n",
        "    file_name = download_url.replace('/', '_')\n",
        "    files_list.append(file_name[41:])\n",
        "    file_name = 'data1/' + file_name[41:]\n",
        "\n",
        "    # Download .txt of the page\n",
        "    urllib.request.urlretrieve(download_url, str(file_name))\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUvuIpuzT8ke",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTOrDXSYUIc3",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Creating data frame\n",
        "A dataframe is first created to keep the documents at their initial state, and the name of each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u857KfY9WXN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lLD0OpiXv5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#insert file names into a df\n",
        "sources = pd.DataFrame(files_list, columns=['file_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgOwPnqCfAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to read the content of the text files\n",
        "def readTxtContent(fileName):\n",
        "  with open('data1/' + fileName, 'r') as file:\n",
        "    return ' ' + file.read().replace('\\n', ' ') + ' '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEVIKHziQv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding a column to the dataframe containing file content\n",
        "sources['file_content'] = sources['file_name'].apply(lambda x: readTxtContent(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AbjD_hb9SQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable containing the documents separately\n",
        "corpus = sources['file_content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybCetXHi9m-y",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Removing stop words, punctuation, short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e-8sf7RayKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1MbU3_seOtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add tokenized documents in dataframe\n",
        "sources['tokens'] = sources['file_content'].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh3ikvdKfQ60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add new column in df with processed tokens\n",
        "sources['tokens_prep'] = sources['tokens'].apply(lambda x: [w.lower() for w in x if (w.isalnum() and len(w) > 3 )])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IrR5gbba5ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# these lines are useful if we want to provide alternate stop words lists (NLTK)\n",
        "# show list of default NLTK Italian stopwords\n",
        "# stopwords.words('italian')\n",
        "# ital_stopwords = stopwords.words('italian')\n",
        "# to append list of words added by user: ital_stopwords.extend(user_input)\n",
        "# to remove words: ital_stopwords.remove(user_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qw4i2O_CTdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spacy list of Stop words (seems to be more complete than NLTK)\n",
        "import spacy\n",
        "from spacy.lang.it.stop_words import STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SBUnxlpCxEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_it_sw = STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDvREaSSiM1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with tokenized documents without sw\n",
        "sources['tokens_prep_nostop'] = sources['tokens_prep'].apply(lambda x: [w for w in x if not w in spacy_it_sw])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKs7aXWLbVWo",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyl0C-xkbLiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euUXP7UHbaN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize with needed language\n",
        "stemmer = SnowballStemmer(\"italian\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CljkLrRmjaot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with stemmed tokens\n",
        "sources['tokens_stemmed'] = sources['tokens_prep_nostop'].apply(lambda x: [stemmer.stem(w) for w in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHKQAqemcgYz",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob8M804chYgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatization is available in multiple languages in Spacy and not in NLTK (only English)\n",
        "# With Spacy, lemmatization is available for 10 languages. There's also a multi-language option that\n",
        "# should be tested if additional languages are needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QAPblFUwf3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python -m spacy download it_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8al8riPXA98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import it_core_news_sm\n",
        "it_nlp = it_core_news_sm.load(disable=['tagger', 'parser', 'ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZHdI_8tmv3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatization function\n",
        "def lemmatize(doc):\n",
        "  lemmatized_doc = []\n",
        "  for w in doc:\n",
        "    w_lemma = [token.lemma_ for token in it_nlp(w)]\n",
        "    lemmatized_doc.append(w_lemma[0])\n",
        "  return lemmatized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-mYWKgSk9CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with lemmatized tokens\n",
        "sources['tokens_lemmatized'] = sources['tokens_prep_nostop'].apply(lambda x: lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvl0MO_FH5yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable with lemmatized tokens\n",
        "lemmatized_corpus = sources['tokens_lemmatized']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8TRLnFPK6p4",
        "colab_type": "text"
      },
      "source": [
        "# 2. Topics with LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr1F0QNdOxy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gensim installation\n",
        "import gensim\n",
        "from gensim.test.utils import common_corpus, common_dictionary\n",
        "from gensim import corpora, models\n",
        "from gensim.models.wrappers import LdaMallet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "530LX-OLRDcP",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Preliminary steps to run LDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlLjmvsQAMy",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxS5Q3aQ7mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = [d.split() for d in lemmatized_corpus] (this is not useful if lemmatized version is used)\n",
        "# Create Dictionary\n",
        "# change \"lemmatized_corpus\" variable by stemmed_corpus or tokenized_corpus_without_sw depending\n",
        "# on which version you would like to work with \n",
        "id2word = corpora.Dictionary(lemmatized_corpus)\n",
        "corpus = [id2word.doc2bow(text) for text in lemmatized_corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadtU7aTQMqg",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLzvb_yC9nyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the number of topics here\n",
        "numtopics = 6\n",
        "ldamodel = models.LdaModel(corpus, id2word=id2word, num_topics=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn70q1uGWx40",
        "colab_type": "text"
      },
      "source": [
        "# Topics and term statistics with PyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ax-Kbh1yBE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _df_with_names(data, index_name, columns_name):\n",
        "    if type(data) == pd.DataFrame:\n",
        "        # we want our index to be numbered\n",
        "        df = pd.DataFrame(data.values)\n",
        "    else:\n",
        "        df = pd.DataFrame(data)\n",
        "    df.index.name = index_name\n",
        "    df.columns.name = columns_name\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8BrjEXB2cCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _series_with_name(data, name):\n",
        "    if type(data) == pd.Series:\n",
        "        data.name = name\n",
        "        # ensures a numeric index\n",
        "        return data.reset_index()[name]\n",
        "    else:\n",
        "        return pd.Series(data, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbuzEmtz_Rym",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Prep from Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5SwEaaM8QKP",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.1. Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IStKuld_8jpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = list(id2word.token2id.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7jAnFU28nvf",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.2. Term freqs and doc length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zw2IzPG9KHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IekrohxF816U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_csc = gensim.matutils.corpus2csc(corpus, num_terms=len(id2word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh8wPJa983kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta = 0.01\n",
        "fnames_argsort = np.asarray(list(id2word.token2id.values()), dtype=np.int_)\n",
        "term_freqs = corpus_csc.sum(axis=1).A.ravel()[fnames_argsort]\n",
        "term_freqs[term_freqs == 0] = beta\n",
        "doc_lengths = corpus_csc.sum(axis=0).A.ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od4pvRZ99ZNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_topics = ldamodel.num_topics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fem1xe7--JPv",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.3. Doc Topic dists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNkkDvqm9gz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gamma, _ = ldamodel.inference(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDOZ7fMC-MO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_topic_dists = gamma / gamma.sum(axis=1)[:, None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlKMqF_P-PFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_topic_dists = _df_with_names(doc_topic_dists, 'doc', 'topic')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSTyhDGh-97W",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.4. Topic Term dists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUfqGnSz_AtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic = ldamodel.state.get_lambda()\n",
        "topic = topic / topic.sum(axis=1)[:, None]\n",
        "topic_term_dists = topic[:, fnames_argsort]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPw_NZBm_eCa",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Prep for viz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvmWCStH_Wfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_term_dists = _df_with_names(topic_term_dists, 'topic', 'term')\n",
        "doc_topic_dists = _df_with_names(doc_topic_dists, 'doc', 'topic')\n",
        "term_frequency = _series_with_name(term_freqs, 'term_frequency')\n",
        "doc_lengths = _series_with_name(doc_lengths, 'doc_length')\n",
        "vocab = _series_with_name(vocab, 'vocab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umWe95RyAIhr",
        "colab_type": "text"
      },
      "source": [
        "### Topic proportion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s51KvZrh_dAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_freq = (doc_topic_dists.T * doc_lengths).T.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfZIS7SaAMAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_proportion = (topic_freq / topic_freq.sum()).sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7OKfX2_AVfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_order = topic_proportion.index\n",
        "# reorder all data based on new ordering of topics\n",
        "topic_freq = topic_freq[topic_order]\n",
        "topic_term_dists = topic_term_dists.iloc[topic_order]\n",
        "doc_topic_dists = doc_topic_dists[topic_order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmokKzyPCTUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# marginal distribution over terms (width of blue bars)\n",
        "term_proportion = term_frequency / term_frequency.sum()\n",
        "\n",
        "# compute the distinctiveness and saliency of the terms:\n",
        "# this determines the R terms that are displayed when no topic is selected\n",
        "topic_given_term = topic_term_dists / topic_term_dists.sum()\n",
        "kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
        "distinctiveness = kernel.sum()\n",
        "saliency = term_proportion * distinctiveness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGcS3qq1DphP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _token_table(topic_info, term_topic_freq, vocab, term_frequency):\n",
        "    # last, to compute the areas of the circles when a term is highlighted\n",
        "    # we must gather all unique terms that could show up (for every combination\n",
        "    # of topic and value of lambda) and compute its distribution over topics.\n",
        "\n",
        "    # term-topic frequency table of unique terms across all topics and all values of lambda\n",
        "    term_ix = topic_info.index.unique()\n",
        "    term_ix = np.sort(term_ix)\n",
        "\n",
        "    top_topic_terms_freq = term_topic_freq[term_ix]\n",
        "    # use the new ordering for the topics\n",
        "    K = len(term_topic_freq)\n",
        "    top_topic_terms_freq.index = range(1, K + 1)\n",
        "    top_topic_terms_freq.index.name = 'Topic'\n",
        "\n",
        "    # we filter to Freq >= 0.5 to avoid sending too much data to the browser\n",
        "    token_table = pd.DataFrame({'Freq': top_topic_terms_freq.unstack()})\\\n",
        "        .reset_index().set_index('term').query('Freq >= 0.5')\n",
        "\n",
        "    token_table['Freq'] = token_table['Freq'].round()\n",
        "    token_table['Term'] = vocab[token_table.index.values].values\n",
        "    # Normalize token frequencies:\n",
        "    token_table['Freq'] = token_table.Freq / term_frequency[token_table.index]\n",
        "    return token_table.sort_values(by=['Term', 'Topic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miscNtvDCpId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R = 30\n",
        "R = min(R, len(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nIL5g4CbSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Order the terms for the \"default\" view by decreasing saliency:\n",
        "default_term_info = pd.DataFrame({\n",
        "  'saliency': saliency,\n",
        "  'Term': vocab,\n",
        "  'Freq': term_frequency,\n",
        "  'Total': term_frequency,\n",
        "  'Category': 'Default'})\n",
        "default_term_info = default_term_info.sort_values(\n",
        "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
        "# Rounding Freq and Total to integer values to match LDAvis code:\n",
        "default_term_info['Freq'] = np.floor(default_term_info['Freq'])\n",
        "default_term_info['Total'] = np.floor(default_term_info['Total'])\n",
        "ranks = np.arange(R, 0, -1)\n",
        "default_term_info['logprob'] = default_term_info['loglift'] = ranks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQPc9TQ-DVcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4358326-c63d-4c2b-f897-d8e81b1c68e8"
      },
      "source": [
        "len(default_term_info)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VLiGb2zFw5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _topic_info(topic_term_dists, topic_proportion, term_frequency, term_topic_freq,\n",
        "                vocab, lambda_step, R, n_jobs):\n",
        "    # marginal distribution over terms (width of blue bars)\n",
        "    term_proportion = term_frequency / term_frequency.sum()\n",
        "\n",
        "    # compute the distinctiveness and saliency of the terms:\n",
        "    # this determines the R terms that are displayed when no topic is selected\n",
        "    topic_given_term = topic_term_dists / topic_term_dists.sum()\n",
        "    kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
        "    distinctiveness = kernel.sum()\n",
        "    saliency = term_proportion * distinctiveness\n",
        "    # Order the terms for the \"default\" view by decreasing saliency:\n",
        "    default_term_info = pd.DataFrame({\n",
        "        'saliency': saliency,\n",
        "        'Term': vocab,\n",
        "        'Freq': term_frequency,\n",
        "        'Total': term_frequency,\n",
        "        'Category': 'Default'})\n",
        "    default_term_info = default_term_info.sort_values(\n",
        "        by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
        "    # Rounding Freq and Total to integer values to match LDAvis code:\n",
        "    default_term_info['Freq'] = np.floor(default_term_info['Freq'])\n",
        "    default_term_info['Total'] = np.floor(default_term_info['Total'])\n",
        "    ranks = np.arange(R, 0, -1)\n",
        "    default_term_info['logprob'] = default_term_info['loglift'] = ranks\n",
        "\n",
        "    # compute relevance and top terms for each topic\n",
        "    log_lift = np.log(topic_term_dists / term_proportion)\n",
        "    log_ttd = np.log(topic_term_dists)\n",
        "    lambda_seq = np.arange(0, 1 + lambda_step, lambda_step)\n",
        "\n",
        "    def topic_top_term_df(tup):\n",
        "        new_topic_id, (original_topic_id, topic_terms) = tup\n",
        "        term_ix = topic_terms.unique()\n",
        "        return pd.DataFrame({'Term': vocab[term_ix],\n",
        "                             'Freq': term_topic_freq.loc[original_topic_id, term_ix],\n",
        "                             'Total': term_frequency[term_ix],\n",
        "                             'logprob': log_ttd.loc[original_topic_id, term_ix].round(4),\n",
        "                             'loglift': log_lift.loc[original_topic_id, term_ix].round(4),\n",
        "                             'Category': 'Topic%d' % new_topic_id})\n",
        "\n",
        "    top_terms = pd.concat(Parallel(n_jobs=n_jobs)\n",
        "                          (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n",
        "                          for ls in _job_chunks(lambda_seq, n_jobs)))\n",
        "    topic_dfs = map(topic_top_term_df, enumerate(top_terms.T.iterrows(), 1))\n",
        "    return pd.concat([default_term_info] + list(topic_dfs), sort=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7PNDqFNF2CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lambda_step=0.01\n",
        "n_jobs=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K7p0kbuGZFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkIUwn2XGnLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _chunks(l, n):\n",
        "    \"\"\" Yield successive n-sized chunks from l.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i + n]\n",
        "\n",
        "\n",
        "def _job_chunks(l, n_jobs):\n",
        "    n_chunks = n_jobs\n",
        "    if n_jobs < 0:\n",
        "        # so, have n chunks if we are using all n cores/cpus\n",
        "        n_chunks = cpu_count() + 1 - n_jobs\n",
        "\n",
        "    return _chunks(l, n_chunks)\n",
        "    \n",
        "def _find_relevance(log_ttd, log_lift, R, lambda_):\n",
        "    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift\n",
        "    return relevance.T.apply(lambda s: s.sort_values(ascending=False).index).head(R)\n",
        "\n",
        "\n",
        "def _find_relevance_chunks(log_ttd, log_lift, R, lambda_seq):\n",
        "    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whN3zkImmoLp",
        "colab_type": "text"
      },
      "source": [
        "## 3.3. Result (data files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUQ6u8X-Fd6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_info = _topic_info(topic_term_dists, topic_proportion,\n",
        "                             term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF4xl3cFUth4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "22ee733c-b2b6-4736-f016-ac9f01f39bff"
      },
      "source": [
        "topic_info"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Freq</th>\n",
              "      <th>Term</th>\n",
              "      <th>Total</th>\n",
              "      <th>loglift</th>\n",
              "      <th>logprob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Default</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>italiano</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>30.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>Default</td>\n",
              "      <td>457.000000</td>\n",
              "      <td>dispaccio</td>\n",
              "      <td>457.000000</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>29.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Default</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>venire</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>28.0000</td>\n",
              "      <td>28.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Default</td>\n",
              "      <td>504.000000</td>\n",
              "      <td>italia</td>\n",
              "      <td>504.000000</td>\n",
              "      <td>27.0000</td>\n",
              "      <td>27.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>Default</td>\n",
              "      <td>311.000000</td>\n",
              "      <td>giornale</td>\n",
              "      <td>311.000000</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>26.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.049451</td>\n",
              "      <td>leggere</td>\n",
              "      <td>165.590347</td>\n",
              "      <td>-0.0748</td>\n",
              "      <td>-6.7254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.078680</td>\n",
              "      <td>parigi</td>\n",
              "      <td>168.948654</td>\n",
              "      <td>-0.0900</td>\n",
              "      <td>-6.7206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.484509</td>\n",
              "      <td>mentire</td>\n",
              "      <td>223.855637</td>\n",
              "      <td>-0.3068</td>\n",
              "      <td>-6.6560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.376319</td>\n",
              "      <td>dovere</td>\n",
              "      <td>219.120758</td>\n",
              "      <td>-0.3023</td>\n",
              "      <td>-6.6728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.053375</td>\n",
              "      <td>quotidiano</td>\n",
              "      <td>206.105118</td>\n",
              "      <td>-0.2930</td>\n",
              "      <td>-6.7248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category         Freq        Term        Total  loglift  logprob\n",
              "458   Default  1001.000000    italiano  1001.000000  30.0000  30.0000\n",
              "278   Default   457.000000   dispaccio   457.000000  29.0000  29.0000\n",
              "995   Default   341.000000      venire   341.000000  28.0000  28.0000\n",
              "456   Default   504.000000      italia   504.000000  27.0000  27.0000\n",
              "384   Default   311.000000    giornale   311.000000  26.0000  26.0000\n",
              "...       ...          ...         ...          ...      ...      ...\n",
              "1463   Topic6     6.049451     leggere   165.590347  -0.0748  -6.7254\n",
              "638    Topic6     6.078680      parigi   168.948654  -0.0900  -6.7206\n",
              "531    Topic6     6.484509     mentire   223.855637  -0.3068  -6.6560\n",
              "295    Topic6     6.376319      dovere   219.120758  -0.3023  -6.6728\n",
              "739    Topic6     6.053375  quotidiano   206.105118  -0.2930  -6.7248\n",
              "\n",
              "[570 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeBhNWixBw-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "topic_info.to_csv('topic_info.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBdiQq7IH-Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_proportion.to_csv('topic_proportion.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P-fm8I_IJl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c5b156d4-a5af-460a-fe85-12529c9c1a82"
      },
      "source": [
        "topic_proportion"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "topic\n",
              "1    0.319186\n",
              "3    0.196606\n",
              "2    0.180878\n",
              "0    0.143365\n",
              "4    0.120596\n",
              "5    0.039370\n",
              "dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    }
  ]
}