{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyldavis_stats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwlEnNvQJNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AZPes5RSYG2",
        "colab_type": "text"
      },
      "source": [
        "# 0. Preliminary step to get sample data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRiBwgFTg2p",
        "colab_type": "text"
      },
      "source": [
        "This preliminary step is reproducing Lorella's workflow Python file:\n",
        "https://i-lab.public.data.uu.nl/vault-ocex/ChroniclItaly%20-%20Italian%20American%20newspapers%20corpus%20from%201898%20to%201920%5B1529330521%5D/original/\n",
        "I just added a folder \"data_1\" to keep all files in one folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK81EVJim0Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir 'data1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O_c4pYzXsP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base URL\n",
        "chronam = 'https://chroniclingamerica.loc.gov/'\n",
        "\n",
        "# Chronicling America search results\n",
        "results = 'https://chroniclingamerica.loc.gov/search/pages/results/?date1=1880&date2=1920&searchType=advanced&language=ita&sequence=1&lccn=2012271201&lccn=sn85066408&lccn=sn85055164&lccn=sn85054967&lccn=sn88064299&lccn=sn84037024&lccn=sn84037025&lccn=sn86092310&proxdistance=5&state=California&state=District+of+Columbia&state=Massachusetts&state=Pennsylvania&state=Piedmont&state=Vermont&state=West+Virginia&rows=100&ortext=&proxtext=&phrasetext=&andtext=&dateFilterType=yearRange&page=11&sort=date'\n",
        "\n",
        "# Count to keep track of downloaded files\n",
        "count = 0\n",
        "\n",
        "# Gets search results in JSON format\n",
        "results_json = results + '&format=json'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQwqRYbydrq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns JSON \n",
        "def get_json(url):\n",
        "    data = requests.get(url)\n",
        "    return(json.loads(data.content))\n",
        "    \n",
        "data = get_json(results_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjv32dwDndnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files_list = []\n",
        "# Cycle through JSON results\n",
        "for page in data['items']:\n",
        "    # Create URL\n",
        "    hit = str(page['id'])\n",
        "    seed = hit + 'ocr.txt'\n",
        "    download_url = chronam + seed\n",
        " \n",
        "    # Create file name\n",
        "    file_name = download_url.replace('/', '_')\n",
        "    files_list.append(file_name[41:])\n",
        "    file_name = 'data1/' + file_name[41:]\n",
        "\n",
        "    # Download .txt of the page\n",
        "    urllib.request.urlretrieve(download_url, str(file_name))\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUvuIpuzT8ke",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTOrDXSYUIc3",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Creating data frame\n",
        "A dataframe is first created to keep the documents at their initial state, and the name of each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u857KfY9WXN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lLD0OpiXv5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#insert file names into a df\n",
        "sources = pd.DataFrame(files_list, columns=['file_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgOwPnqCfAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to read the content of the text files\n",
        "def readTxtContent(fileName):\n",
        "  with open('data1/' + fileName, 'r') as file:\n",
        "    return ' ' + file.read().replace('\\n', ' ') + ' '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEVIKHziQv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding a column to the dataframe containing file content\n",
        "sources['file_content'] = sources['file_name'].apply(lambda x: readTxtContent(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AbjD_hb9SQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable containing the documents separately\n",
        "corpus = sources['file_content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybCetXHi9m-y",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Removing stop words, punctuation, short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e-8sf7RayKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1MbU3_seOtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add tokenized documents in dataframe\n",
        "sources['tokens'] = sources['file_content'].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh3ikvdKfQ60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add new column in df with processed tokens\n",
        "sources['tokens_prep'] = sources['tokens'].apply(lambda x: [w.lower() for w in x if (w.isalnum() and len(w) > 3 )])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IrR5gbba5ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# these lines are useful if we want to provide alternate stop words lists (NLTK)\n",
        "# show list of default NLTK Italian stopwords\n",
        "# stopwords.words('italian')\n",
        "# ital_stopwords = stopwords.words('italian')\n",
        "# to append list of words added by user: ital_stopwords.extend(user_input)\n",
        "# to remove words: ital_stopwords.remove(user_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qw4i2O_CTdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spacy list of Stop words (seems to be more complete than NLTK)\n",
        "import spacy\n",
        "from spacy.lang.it.stop_words import STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SBUnxlpCxEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_it_sw = STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDvREaSSiM1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with tokenized documents without sw\n",
        "sources['tokens_prep_nostop'] = sources['tokens_prep'].apply(lambda x: [w for w in x if not w in spacy_it_sw])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKs7aXWLbVWo",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyl0C-xkbLiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euUXP7UHbaN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize with needed language\n",
        "stemmer = SnowballStemmer(\"italian\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CljkLrRmjaot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with stemmed tokens\n",
        "sources['tokens_stemmed'] = sources['tokens_prep_nostop'].apply(lambda x: [stemmer.stem(w) for w in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHKQAqemcgYz",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob8M804chYgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatization is available in multiple languages in Spacy and not in NLTK (only English)\n",
        "# With Spacy, lemmatization is available for 10 languages. There's also a multi-language option that\n",
        "# should be tested if additional languages are needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QAPblFUwf3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python -m spacy download it_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8al8riPXA98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import it_core_news_sm\n",
        "it_nlp = it_core_news_sm.load(disable=['tagger', 'parser', 'ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZHdI_8tmv3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatization function\n",
        "def lemmatize(doc):\n",
        "  lemmatized_doc = []\n",
        "  for w in doc:\n",
        "    w_lemma = [token.lemma_ for token in it_nlp(w)]\n",
        "    lemmatized_doc.append(w_lemma[0])\n",
        "  return lemmatized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-mYWKgSk9CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with lemmatized tokens\n",
        "sources['tokens_lemmatized'] = sources['tokens_prep_nostop'].apply(lambda x: lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvl0MO_FH5yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable with lemmatized tokens\n",
        "lemmatized_corpus = sources['tokens_lemmatized']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8TRLnFPK6p4",
        "colab_type": "text"
      },
      "source": [
        "# 2. Topics with LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr1F0QNdOxy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gensim installation\n",
        "import gensim\n",
        "from gensim.test.utils import common_corpus, common_dictionary\n",
        "from gensim import corpora, models\n",
        "from gensim.models.wrappers import LdaMallet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "530LX-OLRDcP",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Preliminary steps to run LDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlLjmvsQAMy",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxS5Q3aQ7mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = [d.split() for d in lemmatized_corpus] (this is not useful if lemmatized version is used)\n",
        "# Create Dictionary\n",
        "# change \"lemmatized_corpus\" variable by stemmed_corpus or tokenized_corpus_without_sw depending\n",
        "# on which version you would like to work with \n",
        "dictionary = corpora.Dictionary(lemmatized_corpus)\n",
        "corpus = [dictionary.doc2bow(text) for text in lemmatized_corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadtU7aTQMqg",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLzvb_yC9nyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the number of topics here\n",
        "numtopics = 6\n",
        "ldamodel = models.LdaModel(corpus, num_topics=numtopics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Udb10CNcdsN",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Statistics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBuPuU31gKri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting the corpus into a numpy sparse matrix for efficient arithmetic operations\n",
        "corpus_csc = gensim.matutils.corpus2csc(corpus, num_terms=len(dictionary))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grDhm0M0cshA",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Terms frequency and documents length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4hC14hd1lOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah2fhwuMhm0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms_id = np.asarray(list(dictionary.token2id.values()), dtype=np.int_)\n",
        "sr_terms_id = pd.Series(terms_id, name='vocab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQRgJTP3io5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "term_frequency = corpus_csc.sum(axis=1).A.ravel()[terms_id]\n",
        "sr_term_frequency = pd.Series(term_frequency,name='term_frequency')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAM_ALJklGXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_length = corpus_csc.sum(axis=0).A.ravel()\n",
        "sr_doc_length = pd.Series(doc_length, name='doc_length')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQmOcFUolbp2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Documents topic distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN3FH6Ekln9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# topic weights for each document in the corpus\n",
        "doc_topic_weights = ldamodel.inference(corpus)[0]\n",
        "# normalize weights\n",
        "doc_topic_dists = doc_topic_weights / doc_topic_weights.sum(axis=1)[:, None]\n",
        "# put data into dataframe\n",
        "df_doc_topic_dists = pd.DataFrame(doc_topic_dists)\n",
        "df_doc_topic_dists.index.name = 'doc'\n",
        "df_doc_topic_dists.columns.name = 'topic'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihd72qnTxesY",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Topic terms distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ewaU717x1Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_terms = ldamodel.state.get_lambda() # topics term matrix: https://stackoverflow.com/questions/42289858/extract-topic-word-probability-matrix-in-gensim-ldamodel\n",
        "topic_terms_dist_norm = topic_terms / topic_terms.sum(axis=1)[:, None]\n",
        "topic_term_dists = topic_terms_dist_norm[:, terms_id]\n",
        "topic_term_dists_df = pd.DataFrame(topic_term_dists)\n",
        "df_doc_topic_dists.index.name = 'topic'\n",
        "df_doc_topic_dists.columns.name = 'term'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwhPPmmh6V5T",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Topic proportion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1C2kuE16Zet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_freq = (df_doc_topic_dists.T * sr_doc_length).T.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLsM7MXk62-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_proportion = (topic_freq / topic_freq.sum()).sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AydtPlxv7NXk",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Sorting all data according to topic proportion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gANZxocd7TSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_order = topic_proportion.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah_fX6nN7ZI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_freq_ordered = topic_freq[topic_order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRECWoe87b1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_term_dists_ordered = topic_term_dists_df.iloc[topic_order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmPKrSKY7xUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_topic_dists_ordered = df_doc_topic_dists[topic_order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cdYc7Tb77ln",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.6. Marginal distribution over terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXW1iH938Cdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "term_proportion = sr_term_frequency / sr_term_frequency.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWdo9Yk08wXK",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.7. Saliency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRdBMmK38vRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_given_term = topic_term_dists_ordered / topic_term_dists_ordered.sum()\n",
        "kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
        "distinctiveness = kernel.sum()\n",
        "saliency = term_proportion * distinctiveness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYXmieZR9-7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of terms to display stats for\n",
        "R = 30\n",
        "# note for interface: R = min(R, len(sr_terms_id)) check if R is smaller than the nr of terms,\n",
        "# otherwise take nr of terms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlVLu-jj-VBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stats for all topics\n",
        "default_term_info = pd.DataFrame({\n",
        "  'saliency': saliency,\n",
        "  'Term': sr_terms_id,\n",
        "  'Freq': sr_term_frequency,\n",
        "  'Total': sr_term_frequency,\n",
        "  'Category': 'Default'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdlW1ZvVA7jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort terms for the \"default\" view by decreasing saliency and display only the R first lines:\n",
        "default_term_info = default_term_info.sort_values(\n",
        "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
        "# Rounding Freq and Total to integer values\n",
        "default_term_info['Freq'] = np.floor(default_term_info['Freq'])\n",
        "default_term_info['Total'] = np.floor(default_term_info['Total'])\n",
        "ranks = np.arange(R, 0, -1)\n",
        "default_term_info['logprob'] = default_term_info['loglift'] = ranks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhQaaBI6Dw8M",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.8. Relevance and top terms for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3P_rEUvBTeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_lift = np.log(topic_term_dists_ordered / term_proportion)\n",
        "log_ttd = np.log(topic_term_dists_ordered)\n",
        "lambda_seq = np.arange(0, 1 + 0.01, 0.01) # lambda_step=0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TFQIUJCDUoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def topic_top_term_df(tup):\n",
        "        new_topic_id, (original_topic_id, topic_terms) = tup\n",
        "        term_ix = topic_terms.unique()\n",
        "        return pd.DataFrame({'Term': vocab[term_ix],\n",
        "                             'Freq': term_topic_freq.loc[original_topic_id, term_ix],\n",
        "                             'Total': term_frequency[term_ix],\n",
        "                             'logprob': log_ttd.loc[original_topic_id, term_ix].round(4),\n",
        "                             'loglift': log_lift.loc[original_topic_id, term_ix].round(4),\n",
        "                             'Category': 'Topic%d' % new_topic_id})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymjiXInlEVqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yugW6c1iDiwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f6dbae78-709e-4c83-f32b-f98812fac027"
      },
      "source": [
        "top_terms = pd.concat(Parallel(n_jobs=-1)\n",
        "                          (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n",
        "                          for ls in _job_chunks(lambda_seq, n_jobs))) #n jobs = -1\n",
        "topic_dfs = map(topic_top_term_df, enumerate(top_terms.T.iterrows(), 1))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-7aecc53de489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m top_terms = pd.concat(Parallel(n_jobs=-1)\n\u001b[1;32m      2\u001b[0m                           (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n\u001b[0;32m----> 3\u001b[0;31m                           for ls in _job_chunks(lambda_seq, n_jobs))) #n jobs = -1\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtopic_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_top_term_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_terms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_job_chunks' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYbmi-AFOXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([default_term_info] + list(topic_dfs), sort=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGcS3qq1DphP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _token_table(topic_info, term_topic_freq, vocab, term_frequency):\n",
        "    # last, to compute the areas of the circles when a term is highlighted\n",
        "    # we must gather all unique terms that could show up (for every combination\n",
        "    # of topic and value of lambda) and compute its distribution over topics.\n",
        "\n",
        "    # term-topic frequency table of unique terms across all topics and all values of lambda\n",
        "    term_ix = topic_info.index.unique()\n",
        "    term_ix = np.sort(term_ix)\n",
        "\n",
        "    top_topic_terms_freq = term_topic_freq[term_ix]\n",
        "    # use the new ordering for the topics\n",
        "    K = len(term_topic_freq)\n",
        "    top_topic_terms_freq.index = range(1, K + 1)\n",
        "    top_topic_terms_freq.index.name = 'Topic'\n",
        "\n",
        "    # we filter to Freq >= 0.5 to avoid sending too much data to the browser\n",
        "    token_table = pd.DataFrame({'Freq': top_topic_terms_freq.unstack()})\\\n",
        "        .reset_index().set_index('term').query('Freq >= 0.5')\n",
        "\n",
        "    token_table['Freq'] = token_table['Freq'].round()\n",
        "    token_table['Term'] = vocab[token_table.index.values].values\n",
        "    # Normalize token frequencies:\n",
        "    token_table['Freq'] = token_table.Freq / term_frequency[token_table.index]\n",
        "    return token_table.sort_values(by=['Term', 'Topic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7PNDqFNF2CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K7p0kbuGZFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkIUwn2XGnLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _chunks(l, n):\n",
        "    \"\"\" Yield successive n-sized chunks from l.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i + n]\n",
        "\n",
        "\n",
        "def _job_chunks(l, n_jobs):\n",
        "    n_chunks = n_jobs\n",
        "    if n_jobs < 0:\n",
        "        # so, have n chunks if we are using all n cores/cpus\n",
        "        n_chunks = cpu_count() + 1 - n_jobs\n",
        "\n",
        "    return _chunks(l, n_chunks)\n",
        "    \n",
        "def _find_relevance(log_ttd, log_lift, R, lambda_):\n",
        "    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift\n",
        "    return relevance.T.apply(lambda s: s.sort_values(ascending=False).index).head(R)\n",
        "\n",
        "\n",
        "def _find_relevance_chunks(log_ttd, log_lift, R, lambda_seq):\n",
        "    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whN3zkImmoLp",
        "colab_type": "text"
      },
      "source": [
        "## 3.3. Result (data files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUQ6u8X-Fd6A",
        "colab_type": "code",
        "outputId": "b15c6edf-3e52-4eca-c82e-513a42af34e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "topic_info = _topic_info(topic_term_dists, topic_proportion,\n",
        "                             term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-f358bc47c762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_info = _topic_info(topic_term_dists, topic_proportion,\n\u001b[0;32m----> 2\u001b[0;31m                              term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'term_topic_freq' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF4xl3cFUth4",
        "colab_type": "code",
        "outputId": "22ee733c-b2b6-4736-f016-ac9f01f39bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "topic_info"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Freq</th>\n",
              "      <th>Term</th>\n",
              "      <th>Total</th>\n",
              "      <th>loglift</th>\n",
              "      <th>logprob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Default</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>italiano</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>30.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>Default</td>\n",
              "      <td>457.000000</td>\n",
              "      <td>dispaccio</td>\n",
              "      <td>457.000000</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>29.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Default</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>venire</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>28.0000</td>\n",
              "      <td>28.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Default</td>\n",
              "      <td>504.000000</td>\n",
              "      <td>italia</td>\n",
              "      <td>504.000000</td>\n",
              "      <td>27.0000</td>\n",
              "      <td>27.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>Default</td>\n",
              "      <td>311.000000</td>\n",
              "      <td>giornale</td>\n",
              "      <td>311.000000</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>26.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.049451</td>\n",
              "      <td>leggere</td>\n",
              "      <td>165.590347</td>\n",
              "      <td>-0.0748</td>\n",
              "      <td>-6.7254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.078680</td>\n",
              "      <td>parigi</td>\n",
              "      <td>168.948654</td>\n",
              "      <td>-0.0900</td>\n",
              "      <td>-6.7206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.484509</td>\n",
              "      <td>mentire</td>\n",
              "      <td>223.855637</td>\n",
              "      <td>-0.3068</td>\n",
              "      <td>-6.6560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.376319</td>\n",
              "      <td>dovere</td>\n",
              "      <td>219.120758</td>\n",
              "      <td>-0.3023</td>\n",
              "      <td>-6.6728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>6.053375</td>\n",
              "      <td>quotidiano</td>\n",
              "      <td>206.105118</td>\n",
              "      <td>-0.2930</td>\n",
              "      <td>-6.7248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category         Freq        Term        Total  loglift  logprob\n",
              "458   Default  1001.000000    italiano  1001.000000  30.0000  30.0000\n",
              "278   Default   457.000000   dispaccio   457.000000  29.0000  29.0000\n",
              "995   Default   341.000000      venire   341.000000  28.0000  28.0000\n",
              "456   Default   504.000000      italia   504.000000  27.0000  27.0000\n",
              "384   Default   311.000000    giornale   311.000000  26.0000  26.0000\n",
              "...       ...          ...         ...          ...      ...      ...\n",
              "1463   Topic6     6.049451     leggere   165.590347  -0.0748  -6.7254\n",
              "638    Topic6     6.078680      parigi   168.948654  -0.0900  -6.7206\n",
              "531    Topic6     6.484509     mentire   223.855637  -0.3068  -6.6560\n",
              "295    Topic6     6.376319      dovere   219.120758  -0.3023  -6.6728\n",
              "739    Topic6     6.053375  quotidiano   206.105118  -0.2930  -6.7248\n",
              "\n",
              "[570 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bTzQheAIJWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeBhNWixBw-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "topic_info.to_csv('topic_info.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBdiQq7IH-Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_proportion.to_csv('topic_proportion.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P-fm8I_IJl1",
        "colab_type": "code",
        "outputId": "c5b156d4-a5af-460a-fe85-12529c9c1a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "topic_proportion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "topic\n",
              "1    0.319186\n",
              "3    0.196606\n",
              "2    0.180878\n",
              "0    0.143365\n",
              "4    0.120596\n",
              "5    0.039370\n",
              "dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    }
  ]
}