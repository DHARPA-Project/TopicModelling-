{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyldavis_stats_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwlEnNvQJNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AZPes5RSYG2",
        "colab_type": "text"
      },
      "source": [
        "# 0. Preliminary step to get sample data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRiBwgFTg2p",
        "colab_type": "text"
      },
      "source": [
        "This preliminary step is reproducing Lorella's workflow Python file:\n",
        "https://i-lab.public.data.uu.nl/vault-ocex/ChroniclItaly%20-%20Italian%20American%20newspapers%20corpus%20from%201898%20to%201920%5B1529330521%5D/original/\n",
        "I just added a folder \"data_1\" to keep all files in one folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK81EVJim0Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir 'data1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O_c4pYzXsP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base URL\n",
        "chronam = 'https://chroniclingamerica.loc.gov/'\n",
        "\n",
        "# Chronicling America search results\n",
        "results = 'https://chroniclingamerica.loc.gov/search/pages/results/?date1=1880&date2=1920&searchType=advanced&language=ita&sequence=1&lccn=2012271201&lccn=sn85066408&lccn=sn85055164&lccn=sn85054967&lccn=sn88064299&lccn=sn84037024&lccn=sn84037025&lccn=sn86092310&proxdistance=5&state=California&state=District+of+Columbia&state=Massachusetts&state=Pennsylvania&state=Piedmont&state=Vermont&state=West+Virginia&rows=100&ortext=&proxtext=&phrasetext=&andtext=&dateFilterType=yearRange&page=11&sort=date'\n",
        "\n",
        "# Count to keep track of downloaded files\n",
        "count = 0\n",
        "\n",
        "# Gets search results in JSON format\n",
        "results_json = results + '&format=json'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQwqRYbydrq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns JSON \n",
        "def get_json(url):\n",
        "    data = requests.get(url)\n",
        "    return(json.loads(data.content))\n",
        "    \n",
        "data = get_json(results_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjv32dwDndnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files_list = []\n",
        "# Cycle through JSON results\n",
        "for page in data['items']:\n",
        "    # Create URL\n",
        "    hit = str(page['id'])\n",
        "    seed = hit + 'ocr.txt'\n",
        "    download_url = chronam + seed\n",
        " \n",
        "    # Create file name\n",
        "    file_name = download_url.replace('/', '_')\n",
        "    files_list.append(file_name[41:])\n",
        "    file_name = 'data1/' + file_name[41:]\n",
        "\n",
        "    # Download .txt of the page\n",
        "    urllib.request.urlretrieve(download_url, str(file_name))\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUvuIpuzT8ke",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTOrDXSYUIc3",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Creating data frame\n",
        "A dataframe is first created to keep the documents at their initial state, and the name of each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u857KfY9WXN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lLD0OpiXv5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#insert file names into a df\n",
        "sources = pd.DataFrame(files_list, columns=['file_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgOwPnqCfAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to read the content of the text files\n",
        "def readTxtContent(fileName):\n",
        "  with open('data1/' + fileName, 'r') as file:\n",
        "    return ' ' + file.read().replace('\\n', ' ') + ' '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEVIKHziQv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding a column to the dataframe containing file content\n",
        "sources['file_content'] = sources['file_name'].apply(lambda x: readTxtContent(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AbjD_hb9SQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable containing the documents separately\n",
        "corpus = sources['file_content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybCetXHi9m-y",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Removing stop words, punctuation, short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e-8sf7RayKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1MbU3_seOtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add tokenized documents in dataframe\n",
        "sources['tokens'] = sources['file_content'].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh3ikvdKfQ60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add new column in df with processed tokens\n",
        "sources['tokens_prep'] = sources['tokens'].apply(lambda x: [w.lower() for w in x if (w.isalnum() and len(w) > 3 )])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IrR5gbba5ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# these lines are useful if we want to provide alternate stop words lists (NLTK)\n",
        "# show list of default NLTK Italian stopwords\n",
        "# stopwords.words('italian')\n",
        "# ital_stopwords = stopwords.words('italian')\n",
        "# to append list of words added by user: ital_stopwords.extend(user_input)\n",
        "# to remove words: ital_stopwords.remove(user_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qw4i2O_CTdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spacy list of Stop words (seems to be more complete than NLTK)\n",
        "import spacy\n",
        "from spacy.lang.it.stop_words import STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SBUnxlpCxEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_it_sw = STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDvREaSSiM1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with tokenized documents without sw\n",
        "sources['tokens_prep_nostop'] = sources['tokens_prep'].apply(lambda x: [w for w in x if not w in spacy_it_sw])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKs7aXWLbVWo",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyl0C-xkbLiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euUXP7UHbaN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize with needed language\n",
        "stemmer = SnowballStemmer(\"italian\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CljkLrRmjaot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with stemmed tokens\n",
        "sources['tokens_stemmed'] = sources['tokens_prep_nostop'].apply(lambda x: [stemmer.stem(w) for w in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHKQAqemcgYz",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob8M804chYgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatization is available in multiple languages in Spacy and not in NLTK (only English)\n",
        "# With Spacy, lemmatization is available for 10 languages. There's also a multi-language option that\n",
        "# should be tested if additional languages are needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QAPblFUwf3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python -m spacy download it_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8al8riPXA98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import it_core_news_sm\n",
        "it_nlp = it_core_news_sm.load(disable=['tagger', 'parser', 'ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZHdI_8tmv3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatization function\n",
        "def lemmatize(doc):\n",
        "  lemmatized_doc = []\n",
        "  for w in doc:\n",
        "    w_lemma = [token.lemma_ for token in it_nlp(w)]\n",
        "    lemmatized_doc.append(w_lemma[0])\n",
        "  return lemmatized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-mYWKgSk9CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add column with lemmatized tokens\n",
        "sources['tokens_lemmatized'] = sources['tokens_prep_nostop'].apply(lambda x: lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvl0MO_FH5yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable with lemmatized tokens\n",
        "lemmatized_corpus = sources['tokens_lemmatized']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8TRLnFPK6p4",
        "colab_type": "text"
      },
      "source": [
        "# 2. Topics with LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr1F0QNdOxy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gensim installation\n",
        "import gensim\n",
        "from gensim.test.utils import common_corpus, common_dictionary\n",
        "from gensim import corpora, models\n",
        "from gensim.models.wrappers import LdaMallet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "530LX-OLRDcP",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Preliminary steps to run LDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlLjmvsQAMy",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxS5Q3aQ7mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = [d.split() for d in lemmatized_corpus] (this is not useful if lemmatized version is used)\n",
        "# Create Dictionary\n",
        "# change \"lemmatized_corpus\" variable by stemmed_corpus or tokenized_corpus_without_sw depending\n",
        "# on which version you would like to work with \n",
        "dictionary = corpora.Dictionary(lemmatized_corpus)\n",
        "corpus = [dictionary.doc2bow(text) for text in lemmatized_corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadtU7aTQMqg",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLzvb_yC9nyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the number of topics here\n",
        "numtopics = 6\n",
        "ldamodel = models.LdaModel(corpus, num_topics=numtopics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Udb10CNcdsN",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Statistics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBuPuU31gKri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting the corpus into a numpy sparse matrix for efficient arithmetic operations\n",
        "corpus_csc = gensim.matutils.corpus2csc(corpus, num_terms=len(dictionary))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grDhm0M0cshA",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Terms frequency and documents length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4hC14hd1lOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah2fhwuMhm0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = list(dictionary.token2id.keys())\n",
        "vocab = pd.Series(vocab, name='vocab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFOXBS2gcmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnames_argsort = np.asarray(list(dictionary.token2id.values()), dtype=np.int_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQRgJTP3io5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "term_frequency = corpus_csc.sum(axis=1).A.ravel()[fnames_argsort]\n",
        "term_frequency = pd.Series(term_frequency,name='term_frequency')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAM_ALJklGXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_length = corpus_csc.sum(axis=0).A.ravel()\n",
        "doc_length = pd.Series(doc_length, name='doc_length')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQmOcFUolbp2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Documents topic distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN3FH6Ekln9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# topic weights for each document in the corpus\n",
        "doc_topic_weights = ldamodel.inference(corpus)[0]\n",
        "# normalize weights\n",
        "doc_topic_dists = doc_topic_weights / doc_topic_weights.sum(axis=1)[:, None]\n",
        "# put data into dataframe\n",
        "doc_topic_dists = pd.DataFrame(doc_topic_dists)\n",
        "doc_topic_dists.index.name = 'doc'\n",
        "doc_topic_dists.columns.name = 'topic'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihd72qnTxesY",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Topic terms distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ewaU717x1Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_term = ldamodel.state.get_lambda() # topics term matrix: https://stackoverflow.com/questions/42289858/extract-topic-word-probability-matrix-in-gensim-ldamodel\n",
        "topic_term_dists = topic_term / topic_term.sum(axis=1)[:, None]\n",
        "topic_term_dists = topic_term_dists[:, fnames_argsort]\n",
        "topic_term_dists = pd.DataFrame(topic_term_dists)\n",
        "topic_term_dists.index.name = 'topic'\n",
        "topic_term_dists.columns.name = 'term'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwhPPmmh6V5T",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Topic proportion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1C2kuE16Zet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_freq = (doc_topic_dists.T * doc_length).T.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLsM7MXk62-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_proportion = (topic_freq / topic_freq.sum()).sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AydtPlxv7NXk",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Sorting all data according to topic proportion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gANZxocd7TSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_order = topic_proportion.index\n",
        "topic_freq = topic_freq[topic_order]\n",
        "topic_term_dists = topic_term_dists.iloc[topic_order]\n",
        "doc_topic_dists = doc_topic_dists[topic_order]\n",
        "# token counts for each term-topic combination (widths of red bars)\n",
        "term_topic_freq = (topic_term_dists.T * topic_freq).T\n",
        "term_frequency = np.sum(term_topic_freq, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cdYc7Tb77ln",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.6. Marginal distribution over terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXW1iH938Cdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "term_proportion = term_frequency / term_frequency.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWdo9Yk08wXK",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.7. Saliency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRdBMmK38vRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_given_term = topic_term_dists / topic_term_dists.sum()\n",
        "kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
        "distinctiveness = kernel.sum()\n",
        "saliency = term_proportion * distinctiveness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYXmieZR9-7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of terms to display stats for\n",
        "R = 30\n",
        "# note for interface: R = min(R, len(sr_terms_id)) check if R is smaller than the nr of terms,\n",
        "# otherwise take nr of terms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlVLu-jj-VBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stats for all topics\n",
        "default_term_info = pd.DataFrame({\n",
        "  'saliency': saliency,\n",
        "  'Term': vocab,\n",
        "  'Freq': term_frequency,\n",
        "  'Total': term_frequency,\n",
        "  'Category': 'Default'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdlW1ZvVA7jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort terms for the \"default\" view by decreasing saliency and display only the R first lines:\n",
        "default_term_info = default_term_info.sort_values(\n",
        "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
        "# Rounding Freq and Total to integer values\n",
        "default_term_info['Freq'] = np.floor(default_term_info['Freq'])\n",
        "default_term_info['Total'] = np.floor(default_term_info['Total'])\n",
        "ranks = np.arange(R, 0, -1)\n",
        "default_term_info['logprob'] = default_term_info['loglift'] = ranks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhQaaBI6Dw8M",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.8. Relevance and top terms for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3P_rEUvBTeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_lift = np.log(topic_term_dists / term_proportion)\n",
        "log_ttd = np.log(topic_term_dists)\n",
        "lambda_seq = np.arange(0, 1 + 0.01, 0.01) # lambda_step=0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TFQIUJCDUoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def topic_top_term_df(tup):\n",
        "        new_topic_id, (original_topic_id, topic_terms) = tup\n",
        "        term_ix = topic_terms.unique()\n",
        "        return pd.DataFrame({'Term': vocab[term_ix],\n",
        "                             'Freq': term_topic_freq.loc[original_topic_id, term_ix],\n",
        "                             'Total': term_frequency[term_ix],\n",
        "                             'logprob': log_ttd.loc[original_topic_id, term_ix].round(4),\n",
        "                             'loglift': log_lift.loc[original_topic_id, term_ix].round(4),\n",
        "                             'Category': 'Topic%d' % new_topic_id})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymjiXInlEVqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J14zijsWdlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Technical parameters for further processing\n",
        "lambda_step = 0.01 #interstep distance on which to iterate when computing relevance\n",
        "n_jobs = -1 #number of cores to be used to do the computations (-1 = all cores)\n",
        "lambda_seq = np.arange(0, 1 + lambda_step, lambda_step)\n",
        "def _chunks(l, n):\n",
        "    \"\"\" Yield successive n-sized chunks from l.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i + n]\n",
        "\n",
        "def _job_chunks(l, n_jobs):\n",
        "    n_chunks = n_jobs\n",
        "    if n_jobs < 0:\n",
        "        n_chunks = cpu_count() + 1 - n_jobs\n",
        "\n",
        "    return _chunks(l, n_chunks)\n",
        "\n",
        "def _find_relevance_chunks(log_ttd, log_lift, R, lambda_seq):\n",
        "    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])\n",
        "\n",
        "def _find_relevance(log_ttd, log_lift, R, lambda_):\n",
        "    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift\n",
        "    return relevance.T.apply(lambda s: s.sort_values(ascending=False).index).head(R)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yugW6c1iDiwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_terms = pd.concat(Parallel(n_jobs=-1)\n",
        "                          (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n",
        "                          for ls in _job_chunks(lambda_seq, n_jobs))) #n jobs = -1\n",
        "topic_dfs = map(topic_top_term_df, enumerate(top_terms.T.iterrows(), 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU5WuC0EXjzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_info = pd.concat([default_term_info] + list(topic_dfs), sort=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whN3zkImmoLp",
        "colab_type": "text"
      },
      "source": [
        "## 3.3. Result (data files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqSbZ5vptASD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeBhNWixBw-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_info.to_csv('topic_info.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBdiQq7IH-Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_proportion.to_csv('topic_proportion.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K97k3AMxVdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}