{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mallet_gensim_conversion_test_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7FwlEnNvQJNG",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import urllib\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6AZPes5RSYG2"
      },
      "source": [
        "# 0. Preliminary step to get the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJIf-2J0kifU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if the filtered documents file has already been generated by previously running the notebook\n",
        "# upload the file in notebook env and call it here\n",
        "# run the cell that mounts google drive if you want to save output there\n",
        "# then set the output folder and run the output folder cell\n",
        "# after G Drive is mounted and the output folder set, go directly to step 1.3 without running the cells in between\n",
        "# corpus_df = pd.read_csv('documents_list.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "loJLAa_Jf5Yq"
      },
      "source": [
        "Getting data from sharable google drive folder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VK81EVJim0Jc",
        "colab": {}
      },
      "source": [
        "# link to folder: https://drive.google.com/drive/folders/18TjiltRr8CFlx0aPcLsnKBr5iyeiQxWc?usp=sharing\n",
        "# upload data folder to your drive root folder 'My Drive' (It is the default folder)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t8mKSMpvh7Xr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7f40a39b-c486-4953-fb96-7a878ccba4dc"
      },
      "source": [
        "# connect your drive to Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# after running this cell, open the url that displays below from your gmail account\n",
        "# copy the code that is displayed \n",
        "# paste the code into the cell below when prompted and then press enter"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcelXsQe59E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = '/content/drive/My Drive/data_tm_workflow/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz8Y5ZMJcYdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the output folder in the drive (the csv files with the results of the process will be downloaded there)\n",
        "# first create the empty folder in the drive\n",
        "output_folder = '/content/drive/My Drive/tests2_mallet'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AUvuIpuzT8ke"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MTOrDXSYUIc3"
      },
      "source": [
        "## 1.1. Creating data frame\n",
        "A dataframe is first created to keep the documents at their initial state, and the name of each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EFg24uulSAjU",
        "colab": {}
      },
      "source": [
        "files_list = os.listdir(folder_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8lLD0OpiXv5Y",
        "colab": {}
      },
      "source": [
        "#insert file names into a df\n",
        "sources = pd.DataFrame(files_list, columns=['file_name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lThO8DOoxIDj",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Adding columns for dates, publications and filtering dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ko2sWRfxUYu",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1. dates, publications\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tevIGmzTxV1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sbxDR8OxZxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get publication ref from file name\n",
        "def get_ref(file):\n",
        "  ref_match = re.findall(r'(\\w+\\d+)_\\d{4}-\\d{2}-\\d{2}_',file)\n",
        "  return ref_match[0]\n",
        "\n",
        "# get date from file name\n",
        "def get_date(file):\n",
        "  date_match = re.findall(r'_(\\d{4}-\\d{2}-\\d{2})_',file)\n",
        "  return date_match[0]\n",
        "\n",
        "# get year from file name\n",
        "def get_year(file):\n",
        "  year_match = re.findall(r'_(\\d{4})-\\d{2}-\\d{2}_',file)\n",
        "  return year_match[0]\n",
        "\n",
        "# get month from file name\n",
        "def get_month(file):\n",
        "  month_match = re.findall(r'_\\d{4}-(\\d{2})-\\d{2}_',file)\n",
        "  return month_match[0]\n",
        "\n",
        "# get day from file name\n",
        "def get_day(file):\n",
        "  month_match = re.findall(r'_\\d{4}-\\d{2}-(\\d{2})_',file)\n",
        "  return month_match[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA1WCnSFxeRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sources['date'] = sources['file_name'].apply(lambda x: get_date(x))\n",
        "sources['year'] = sources['file_name'].apply(lambda x: get_year(x))\n",
        "sources['month'] = sources['file_name'].apply(lambda x: get_month(x))\n",
        "sources['day'] = sources['file_name'].apply(lambda x: get_day(x))\n",
        "sources['publication'] = sources['file_name'].apply(lambda x: get_ref(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezYPJg2axiLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add publication names\n",
        "def get_pub_name(pub_number):\n",
        "    if (pub_number == 'sn85066408'):\n",
        "        return 'L\\'Italia'\n",
        "    elif (pub_number == '2012271201'):\n",
        "        return 'Cronaca Sovversiva'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v0-LjG4xl0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sources['publication_name'] = sources['publication'].apply(lambda x: get_pub_name(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLDYbjnqxrCN",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2. Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NicsSId4xz4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from datetime import timedelta, date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu78NIAex2z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start from 06.06.1903 and finish 01.05.1919\n",
        "date_ref_1 = date(1903,6,6)\n",
        "date_ref_2 = date(1919,5,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06AdSGRNx7Ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_by_date(date_item,date_ref_1,date_ref_2):\n",
        "    year = re.findall(r'(\\d{4})-\\d{2}-\\d{2}',date_item)[0]\n",
        "    month = re.findall(r'\\d{4}-(\\d{2})-\\d{2}',date_item)[0]\n",
        "    day = re.findall(r'\\d{4}-\\d{2}-(\\d{2})',date_item)[0]\n",
        "    file_date = date(int(year),int(month),int(day))\n",
        "    if (date_ref_1 <= file_date <= date_ref_2):\n",
        "        return 'included'\n",
        "    else:\n",
        "        return 'not included'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UmLfsQjx-sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sources['status'] = sources['date'].apply(lambda x: filter_by_date(x,date_ref_1,date_ref_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdadRVCWyCDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variable containing the filtered documents\n",
        "corpus_df = sources[sources['status'] == 'included'].copy().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m794M-EPz_Lt",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.3 Adding text content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0PgOwPnqCfAe",
        "colab": {}
      },
      "source": [
        "# read the content of the text files\n",
        "def readTxtContent(fileName):\n",
        "  with open(folder_path + fileName, 'r') as file:\n",
        "    return ' ' + file.read().replace('\\n', ' ') + ' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MZEVIKHziQv2",
        "colab": {}
      },
      "source": [
        "# add a column to the dataframe containing file content\n",
        "corpus_df['file_content'] = corpus_df['file_name'].apply(lambda x: readTxtContent(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANmN9EwC36XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_df.to_csv(output_folder + '/documents_list.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ybCetXHi9m-y"
      },
      "source": [
        "## 1.3 Removing stop words, punctuation, short words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjphk8Sk59Fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a8ef8577-70c4-4c26-cb07-723a1d41dbc3"
      },
      "source": [
        "! pip install nltk"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6e-8sf7RayKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ef1c36de-3b61-405d-a880-5a28b038edf3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1MbU3_seOtJ",
        "colab": {}
      },
      "source": [
        "# add tokenized documents in dataframe\n",
        "corpus_df['tokens'] = corpus_df['file_content'].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vh3ikvdKfQ60",
        "colab": {}
      },
      "source": [
        "# possible user options:\n",
        "# .isalnum() to removes tokens that include numbers\n",
        "# .isalpha() to remove all tokens that contain more than letters (punctuation and numbers)\n",
        "# .isdecimal() to remove tokens that contain only decimals\n",
        "# .isdigit() to remove tokens that contain only digits\n",
        "\n",
        "# add new column in df with processed tokens (here: keeping only alpha tokens longer than 3 characters + lowercasing)\n",
        "corpus_df['doc_prep'] = corpus_df['tokens'].apply(lambda x: [w.lower() for w in x if (w.isalpha() and len(w) > 2 )])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We2Ph83Y59F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# link to custom stop words: https://drive.google.com/file/d/1VVfW6AKPbb7_fICOG73lEgkXmmZ6BkpC/view?usp=sharing\n",
        "# Upload stop words list into Colab files before proceeding with the next cells"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-l00vPyShTM",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "ital_stopwords = stopwords.words('italian')\n",
        "en_stopwords = stopwords.words('english')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "74eVFiitFFnO",
        "colab": {}
      },
      "source": [
        "stop_words = pd.read_csv('stop_words.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uw-or9DzIVI2",
        "colab": {}
      },
      "source": [
        "stopwords = stop_words['stopword'].values.tolist()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLpy-SOmhOmr",
        "colab": {}
      },
      "source": [
        "# add english stop words list to custom stopwords \n",
        "stopwords.extend(en_stopwords)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3IrR5gbba5ho",
        "colab": {}
      },
      "source": [
        "# to append list of words added by user: ital_stopwords.extend(user_input)\n",
        "# to remove words: ital_stopwords.remove(user_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5SBUnxlpCxEa",
        "colab": {}
      },
      "source": [
        "# add column with tokenized documents without sw\n",
        "corpus_df['doc_prep_nostop'] = corpus_df['doc_prep'].apply(lambda x: [w for w in x if not w in stopwords])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6S_6yx1UmIbZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "20baa494-c0ea-43e5-844f-031058ec41f6"
      },
      "source": [
        "corpus_df['doc_prep_nostop']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [nura, dtfip, verrmo, assioma, auanto, barba, ...\n",
              "1      [saturday, january, barre, vermont, sabato, ge...\n",
              "2      [annj, xii, iodio, mite, umberto, santo, costi...\n",
              "3      [vili, entered, brusco, svolto, storia, partit...\n",
              "4      [scoi, ietti, lez, actf, àttof, coij, peri, it...\n",
              "                             ...                        \n",
              "766    [ionn, imperversa, giungono, spiaggie, patria,...\n",
              "767    [ass, ittc, ass, tìii, eie, alt, sss, lynn, au...\n",
              "768    [num, xii, magnifico, pertinacia, levato, pean...\n",
              "769    [ann, rhe, fcr, rivo, ragioni, economiche, sfa...\n",
              "770    [newspapet, objection, anvo, nura, mmmmmmm, an...\n",
              "Name: doc_prep_nostop, Length: 771, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZHRCw-TLGPK",
        "colab": {}
      },
      "source": [
        "# set the variable to use for topic modelling (if no further options are used)\n",
        "corpus_model = corpus_df['doc_prep_nostop']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAfTMWcX59GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the data after pre-processing in the output folder for verification of pre-processing steps\n",
        "# corpus_df.to_csv(output_folder + '/corpus_df.csv')\n",
        "corpus_df.to_csv(output_folder + '/corpus_df.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YHKQAqemcgYz"
      },
      "source": [
        "## 1.4 Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ob8M804chYgh",
        "colab": {}
      },
      "source": [
        "# Lemmatization is available in multiple languages in Spacy and not in NLTK (only English)\n",
        "# With Spacy, lemmatization is available for 10 languages. There's also a multi-language option that\n",
        "# should be tested if additional languages are needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spP6fsv-59GO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e57d264a-be89-47d0-c8e1-7f5c5e8ea988"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2QAPblFUwf3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "2412f505-1a4a-425e-8a66-13127460ad4a"
      },
      "source": [
        "!python3 -m spacy download it_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: it_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-2.2.5/it_core_news_sm-2.2.5.tar.gz#egg=it_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from it_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->it_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->it_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->it_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->it_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->it_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->it_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->it_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('it_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8al8riPXA98n",
        "colab": {}
      },
      "source": [
        "import it_core_news_sm\n",
        "it_nlp = it_core_news_sm.load(disable=['tagger', 'parser', 'ner'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YZHdI_8tmv3y",
        "colab": {}
      },
      "source": [
        "# lemmatization function\n",
        "def lemmatize(doc):\n",
        "  lemmatized_doc = []\n",
        "  for w in doc:\n",
        "    w_lemma = [token.lemma_ for token in it_nlp(w)]\n",
        "    lemmatized_doc.append(w_lemma[0])\n",
        "  return lemmatized_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-mYWKgSk9CW",
        "colab": {}
      },
      "source": [
        "# add column with lemmatized tokens - directly from the tokens as preprocessing has already been done\n",
        "corpus_df['doc_lemmatized'] = corpus_df['doc_prep_nostop'].apply(lambda x: lemmatize(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvl0MO_FH5yH",
        "colab": {}
      },
      "source": [
        "# variable with lemmatized tokens\n",
        "lemmatized_corpus = corpus_df['doc_lemmatized']\n",
        "# the lemmatized version is not used in this example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o8TRLnFPK6p4"
      },
      "source": [
        "# 2. Topics with LDA Mallet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdwV8h_b59GX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "64ff4523-de86-434f-f569-4bf23a53e21d"
      },
      "source": [
        "#Gensim installation\n",
        "! pip install gensim"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.22)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.22 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.22)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.22->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.22->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nxqE7mp2CL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# installation setup that works for Mallet: https://github.com/polsci/colab-gensim-mallet/blob/master/topic-modeling-with-colab-gensim-mallet.ipynb\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0ctJB2V2DyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VllmMhb2Gzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['MALLET_HOME'] = '/content/mallet-2.0.8'\n",
        "mallet_path = '/content/mallet-2.0.8/bin/mallet'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fr1F0QNdOxy3",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.test.utils import common_corpus, common_dictionary\n",
        "from gensim import corpora, models\n",
        "from gensim.models.wrappers import LdaMallet"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "530LX-OLRDcP"
      },
      "source": [
        "## 2.1 Preliminary steps to run LDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuVJZqPE2gMA",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Creating the dictionary, optional filtering of extreme values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQCa_QvL2vQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you use lemmatized version replace \"corpus_model\" by lemmatized_corpus\n",
        "id2word = corpora.Dictionary(corpus_model)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kyAS5ON2x4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word.filter_extremes(no_below=5)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GZlLjmvsQAMy"
      },
      "source": [
        "### 2.1.2 Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UzxS5Q3aQ7mh",
        "colab": {}
      },
      "source": [
        "corpus = [id2word.doc2bow(text) for text in corpus_model]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qadtU7aTQMqg"
      },
      "source": [
        "## 2.2 LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAG4fnuMAkER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the nr of topics\n",
        "num_topics = 2"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8nlp1W32sQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare results between Mallet and Mallet translated back to Gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtmuygzBANHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1f9c7e1e-c735-4a57-d43b-996be4ffd592"
      },
      "source": [
        "model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q06qahdO7d0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# translate back mallet model into gensim format\n",
        "model2 = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTmKOqquZgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y8D6V_32gBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the first array number is the topic id for which printing the topic words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMJpY-zttyhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match_w0 = re.findall(r'\"(\\w+)\"',model.print_topics(num_words=150)[1][1])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QgJzEeIxsgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match_w1 = re.findall(r'\"(\\w+)\"',model2.print_topics(num_words=150)[1][1])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SC38Zwyt6QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topic0 = pd.DataFrame(match_w0, columns=['words_topic_0_mallet'])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skcEWRukweJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topic0 = df_topic0.sort_values(['words_topic_0_mallet']).reset_index().copy()"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fgQXHiJvpRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topic1 = pd.DataFrame(match_w1, columns=['words_topic_0_mallet_to_gensim'])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cThKC3Lwg9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topic1 = df_topic1.sort_values(['words_topic_0_mallet_to_gensim']).reset_index().copy()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHwNdZEMvySD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topics = pd.concat([df_topic0,df_topic1],axis=1)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIPkJDh_t-8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topics.to_csv(output_folder +'/topic_words_1.csv')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxI53458uA7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}